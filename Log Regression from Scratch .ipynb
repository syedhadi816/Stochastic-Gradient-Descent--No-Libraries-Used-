{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:22: UserWarning: loadtxt: Empty input file: \"/Users/syedhadi/Desktop/Assignment2/Dataset/train/neg/2425_4.txt\"\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:22: UserWarning: loadtxt: Empty input file: \"/Users/syedhadi/Desktop/Assignment2/Dataset/train/neg/4179_4.txt\"\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:22: UserWarning: loadtxt: Empty input file: \"/Users/syedhadi/Desktop/Assignment2/Dataset/train/pos/5122_9.txt\"\n"
     ]
    }
   ],
   "source": [
    "X1 = list() #  count(positive words) ∈ review\n",
    "X2 = list() #  count(negative words) ∈ review\n",
    "X3 = list() #  Star Rating (1-10 scale)\n",
    "X4 = list() #  log(word count of review)\n",
    "X5 = list() #  1 if “no” ∈ review, 0 otherwise\n",
    "X6 = list() #  1 if “!” ∈ review, 0 otherwise\n",
    "Y  = list() #  1 if positive, 0 otherwise\n",
    "Ntrain = os.listdir('/Users/syedhadi/Desktop/Assignment2/Dataset/train/neg') #Negative Reviews Directory \n",
    "Ptrain = os.listdir('/Users/syedhadi/Desktop/Assignment2/Dataset/train/pos') #Positive Reviews Directory \n",
    "\n",
    "def read_file(directory): #sorts the content of a review into variables\n",
    "    Ncount= 0\n",
    "    Pcount = 0\n",
    "    E = 0\n",
    "    no = 0\n",
    "    length=0\n",
    "    try:\n",
    "        Ncount= 0\n",
    "        Pcount = 0\n",
    "        E = 0\n",
    "        no = 0\n",
    "        iterator = np.loadtxt(directory,dtype='str' ,encoding = \"ISO-8859-1\")\n",
    "        if (len(iterator)<2):\n",
    "            return [Pcount, Ncount, length,no,E]\n",
    "        neg_words = np.loadtxt(os.path.join('/Users/syedhadi/Desktop/Assignment2/Dataset/negative-words.txt'),dtype='str',encoding = \"ISO-8859-1\")\n",
    "        pos_words = np.loadtxt(os.path.join('/Users/syedhadi/Desktop/Assignment2/Dataset/positive-words.txt'),dtype='str',encoding = \"ISO-8859-1\")\n",
    "        for obj in iterator:\n",
    "            if obj in neg_words:\n",
    "                Ncount += 1\n",
    "            if obj in pos_words:\n",
    "                Pcount += 1\n",
    "            if obj == '!':\n",
    "                E = 1\n",
    "            if obj == 'no':\n",
    "                no = 1       \n",
    "        length = len(iterator)\n",
    "        return [Pcount, Ncount, length,no,E]\n",
    "    except:\n",
    "        print('empty = '+directory)\n",
    "        return[Pcount, Ncount, length,no,E]\n",
    "\n",
    "if('.DS_Store' in Ntrain): \n",
    "    a=Ntrain.index('.DS_Store')\n",
    "    del Ntrain[a]\n",
    "if('.DS_Store' in Ptrain): \n",
    "    b=Ptrain.index('.DS_Store')\n",
    "    del Ptrain[b]\n",
    "\n",
    "#k=0\n",
    "\n",
    "for i in Ntrain:\n",
    "    if os.stat('/Users/syedhadi/Desktop/Assignment2/Dataset/train/neg/'+i).st_size == 0:\n",
    "        continue\n",
    "    file_stats = read_file('/Users/syedhadi/Desktop/Assignment2/Dataset/train/neg/'+i)\n",
    "    if (file_stats[2]==0):\n",
    "        continue \n",
    "    X1.append(file_stats[0])\n",
    "    X2.append(file_stats[1])\n",
    "    X3.append(int(i[i.find('_')+1]))\n",
    "    X4.append(np.log(file_stats[2]))\n",
    "    X5.append(file_stats[3])\n",
    "    X6.append(file_stats[4])\n",
    "    Y.append(0)\n",
    "    #k=k+1\n",
    "    #if(k==12499):\n",
    "        #break\n",
    "#k=0\n",
    "for i in Ptrain:\n",
    "    if os.stat('/Users/syedhadi/Desktop/Assignment2/Dataset/train/pos/'+i).st_size == 0:\n",
    "        continue\n",
    "    file_stats = read_file('/Users/syedhadi/Desktop/Assignment2/Dataset/train/pos/'+i)\n",
    "    if (file_stats[2]==0):\n",
    "        continue \n",
    "    X1.append(file_stats[0])\n",
    "    X2.append(file_stats[1])\n",
    "    if(i[i.find('_')+1]== '1'):\n",
    "        X3.append(10)\n",
    "    else:\n",
    "        X3.append(int(i[i.find('_')+1]))\n",
    "    X4.append(np.log(file_stats[2]))\n",
    "    X5.append(file_stats[3])\n",
    "    X6.append(file_stats[4])\n",
    "    Y.append(1)\n",
    "    #k=k+1\n",
    "    #if(k==12499):\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append everything in one matrix, and Append the 1's in X\n",
    "\n",
    "X0= np.ones(len(X1))\n",
    "X= np.array([X0,X1,X2,X3,X4,X5,X6])\n",
    "\n",
    "X= np.transpose(X)\n",
    "\n",
    "\n",
    "#Cost Function \n",
    "def Cost(Theta, X , y):\n",
    "\n",
    "    L1= np.zeros(m)\n",
    "    L2= np.zeros(m)\n",
    "    \n",
    "\n",
    "    L1[i] = (y* np.log(prediction(X,Theta)))  \n",
    "    L2[i] = ((1-y)*np.log(1-prediction(X,Theta)))\n",
    "    \n",
    "    L= (-L1 - L2)\n",
    "    l= np.mean(L)\n",
    "    return (l)\n",
    "\n",
    "#Prediction Function \n",
    "def prediction(X,Theta):\n",
    "    z = np.dot(X,Theta)\n",
    "    pred= 1/(1+ np.exp(-z))\n",
    "    return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stochastic Gradient Descent Function, return parameters calculated by SGD\n",
    "def SGD(X, Y, lr, iters):\n",
    "    \n",
    "    m= len(Y) #trainnig data size\n",
    "    n = X[0,:].size # number of features \n",
    "    Params = np.zeros(n)\n",
    "    Ptemp = np.zeros(n)\n",
    "    for epoch in range (iters):\n",
    "        pick = rd.randint(1, m-1)\n",
    "        g1 = (lr)*(prediction(X[pick,:],Params)- Y[pick])\n",
    "        GradVector = g1 * X[pick,:]\n",
    "        Ptemp= Params - GradVector\n",
    "        Params = Ptemp\n",
    "    return Params\n",
    "    \n",
    "SGD_Params = SGD(X,Y,0.01, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batch Gradient Descent Function, return parameters calculated by BGD\n",
    "def BGD(X, Y, lr, iters):\n",
    "    m= len(Y) #trainnig data size\n",
    "    n = X[0,:].size # number of features \n",
    "    Params = np.zeros(n)\n",
    "    Ptemp = np.zeros(n)\n",
    "    for epoch in range (iters):\n",
    "        Sum = np.zeros(n)\n",
    "        for i in range (m):\n",
    "            Sum += (prediction(X[i,:],Params)- Y[i])*X[i,:]\n",
    "        GradVector = (lr/m) * Sum\n",
    "        Ptemp= Params - GradVector\n",
    "        Params = Ptemp\n",
    "    return Params\n",
    "   \n",
    "\n",
    "BGD_Params = BGD(X,Y, 0.1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty = /Users/syedhadi/Desktop/Assignment2/Dataset/test/neg/7422_1.txt\n",
      "empty = /Users/syedhadi/Desktop/Assignment2/Dataset/test/pos/8317_10.txt\n"
     ]
    }
   ],
   "source": [
    "#Test data used here Onwards\n",
    "\n",
    "#loading data, processing it and storing features in variables \n",
    "\n",
    "T1 = list() #  count(positive words) ∈ review\n",
    "T2 = list() #  count(negative words) ∈ review\n",
    "T3 = list() #  Star Rating (1-10 scale)\n",
    "T4 = list() #  log(word count of review)\n",
    "T5 = list() #  1 if “no” ∈ review, 0 otherwise\n",
    "T6 = list() #  1 if “!” ∈ review, 0 otherwise\n",
    "Ty  = list() #  1 if positive, 0 otherwise\n",
    "Ntest = os.listdir('/Users/syedhadi/Desktop/Assignment2/Dataset/test/neg') #Negative Reviews Directory \n",
    "Ptest = os.listdir('/Users/syedhadi/Desktop/Assignment2/Dataset/test/pos') #Positive Reviews Directory \n",
    "\n",
    "def read_file(directory): #sorts the content of a review into variables\n",
    "    Ncount= 0\n",
    "    Pcount = 0\n",
    "    E = 0\n",
    "    no = 0\n",
    "    length=0\n",
    "    try:\n",
    "        Ncount= 0\n",
    "        Pcount = 0\n",
    "        E = 0\n",
    "        no = 0\n",
    "        iterator = np.loadtxt(directory,dtype='str' ,encoding = \"ISO-8859-1\")\n",
    "        if (len(iterator)<2):\n",
    "            return [Pcount, Ncount, length,no,E]\n",
    "        neg_words = np.loadtxt(os.path.join('/Users/syedhadi/Desktop/Assignment2/Dataset/negative-words.txt'),dtype='str',encoding = \"ISO-8859-1\")\n",
    "        pos_words = np.loadtxt(os.path.join('/Users/syedhadi/Desktop/Assignment2/Dataset/positive-words.txt'),dtype='str',encoding = \"ISO-8859-1\")\n",
    "        for obj in iterator:\n",
    "            if obj in neg_words:\n",
    "                Ncount += 1\n",
    "            if obj in pos_words:\n",
    "                Pcount += 1\n",
    "            if obj == '!':\n",
    "                E = 1\n",
    "            if obj == 'no':\n",
    "                no = 1       \n",
    "        length = len(iterator)\n",
    "        return [Pcount, Ncount, length,no,E]\n",
    "    except:\n",
    "        print('empty = '+directory)\n",
    "        return[Pcount, Ncount, length,no,E]\n",
    "\n",
    "if('.DS_Store' in Ntest): \n",
    "    a=Ntest.index('.DS_Store')\n",
    "    del Ntest[a]\n",
    "if('.DS_Store' in Ptest): \n",
    "    b=Ptest.index('.DS_Store')\n",
    "    del Ptest[b]\n",
    "\n",
    "#k=0\n",
    "\n",
    "for i in Ntest:\n",
    "    if os.stat('/Users/syedhadi/Desktop/Assignment2/Dataset/test/neg/'+i).st_size == 0:\n",
    "        continue\n",
    "    file_stats = read_file('/Users/syedhadi/Desktop/Assignment2/Dataset/test/neg/'+i)\n",
    "    if (file_stats[2]==0):\n",
    "        continue \n",
    "    T1.append(file_stats[0])\n",
    "    T2.append(file_stats[1])\n",
    "    T3.append(int(i[i.find('_')+1]))\n",
    "    T4.append(np.log(file_stats[2]))\n",
    "    T5.append(file_stats[3])\n",
    "    T6.append(file_stats[4])\n",
    "    Ty.append(0)\n",
    "    #k=k+1\n",
    "    #if(k==12499):\n",
    "        #break\n",
    "#k=0\n",
    "for i in Ptest:\n",
    "    if os.stat('/Users/syedhadi/Desktop/Assignment2/Dataset/test/pos/'+i).st_size == 0:\n",
    "        continue\n",
    "    file_stats = read_file('/Users/syedhadi/Desktop/Assignment2/Dataset/test/pos/'+i)\n",
    "    if (file_stats[2]==0):\n",
    "        continue \n",
    "    T1.append(file_stats[0])\n",
    "    T2.append(file_stats[1])\n",
    "    if(i[i.find('_')+1]== '1'):\n",
    "        T3.append(10)\n",
    "    else:\n",
    "        T3.append(int(i[i.find('_')+1]))\n",
    "    T4.append(np.log(file_stats[2]))\n",
    "    T5.append(file_stats[3])\n",
    "    T6.append(file_stats[4])\n",
    "    Ty.append(1)\n",
    "    #k=k+1\n",
    "    #if(k==12499):\n",
    "        #break\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "T0= np.ones(len(T1))\n",
    "T= np.array([T0,T1,T2,T3,T4,T5,T6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the test data, and storing predicted labels \n",
    "\n",
    " \n",
    "\n",
    "m= T[0,:].size #size of examples \n",
    "n= T[:,0].size #number of features \n",
    "SGDtest= np.zeros(m)\n",
    "BGDtest= np.zeros(m)\n",
    "#Storing with SGD hyperparameters\n",
    "for i in range (m):\n",
    "    a = prediction(T[:,i],SGD_Params)\n",
    "    if a<0.5:\n",
    "        SGDtest[i]=0\n",
    "    if a>=0.5:\n",
    "        SGDtest[i]=1\n",
    "        \n",
    "#storing with BGD hyperparameters\n",
    "\n",
    "for i in range (m):\n",
    "    a = prediction(T[:,i],BGD_Params)\n",
    "    if a<0.5:\n",
    "        BGDtest[i]=0\n",
    "    if a>=0.5:\n",
    "        BGDtest[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Confusion Matrix \n",
    "def Confusion (G,S): #Gold labels, System generated labels \n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    fp = 0\n",
    "    tp = 0\n",
    "    m= len(S)\n",
    "\n",
    "    for i in range (m):\n",
    "        if S[i]== G[i]:\n",
    "            #print('ok')\n",
    "            if G[i] == 1:\n",
    "                tp = tp+1\n",
    "            if G[i] ==0:\n",
    "                tn = tn+1\n",
    "        if S[i] != G[i]:\n",
    "            if G[i] == 1:\n",
    "                fn = fn+1\n",
    "            if G[i] == 0:\n",
    "                fp = fp +1\n",
    "    Result = np.array([tn, tp, fn, fp])\n",
    "    return (Result)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BGD Results:\n",
      "Tn =  12474\n",
      "Tp =  12495\n",
      "Fn =  4\n",
      "Fp =  25\n",
      "SGD Results:\n",
      "Tn =  12470\n",
      "Tp =  12499\n",
      "Fn =  0\n",
      "Fp =  29\n"
     ]
    }
   ],
   "source": [
    "#Throwing stuff into confusion matrix for testing \n",
    "\n",
    "#BGD Params \n",
    "B = Confusion (Ty, BGDtest)\n",
    "\n",
    "print('BGD Results:')\n",
    "print('Tn = ',B[0])\n",
    "print('Tp = ',B[1])\n",
    "print('Fn = ',B[2])\n",
    "print('Fp = ',B[3])\n",
    "\n",
    "#SGD Params \n",
    "S = Confusion (Ty, SGDtest)\n",
    "\n",
    "print('SGD Results:')\n",
    "print('Tn = ',S[0])\n",
    "print('Tp = ',S[1])\n",
    "print('Fn = ',S[2])\n",
    "print('Fp = ',S[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BGD Results 2\n",
      "Precision =  0.9980031948881789\n",
      "Recall =  0.9996799743979519\n",
      "Accuracy =  0.9988399071925754\n",
      "F1 Measure =  0.9988408809304928\n",
      "############       #########\n",
      "SGD Results 2\n",
      "Precision =  0.9976851851851852\n",
      "Recall =  1.0\n",
      "Accuracy =  0.9988399071925754\n",
      "F1 Measure =  0.9988412514484357\n"
     ]
    }
   ],
   "source": [
    "print('BGD Results 2')\n",
    "Tn = B[0]\n",
    "Tp = B[1]\n",
    "Fn = B[2]\n",
    "Fp = B[3]\n",
    "\n",
    "P= Tp/(Tp+Fp)\n",
    "A= (Tp+Tn)/(Tp+Tn+Fp+Fn)\n",
    "R= Tp/(Tp+Fn)\n",
    "F1= (2*R*P)/(R+P)\n",
    "\n",
    "print('Precision = ',P)\n",
    "print('Recall = ',R)\n",
    "print('Accuracy = ', A)\n",
    "print('F1 Measure = ', F1)\n",
    "print('############       #########')\n",
    "print('SGD Results 2')\n",
    "Tn = S[0]\n",
    "Tp = S[1]\n",
    "Fn = S[2]\n",
    "Fp = S[3]\n",
    "\n",
    "P= Tp/(Tp+Fp)\n",
    "A= (Tp+Tn)/(Tp+Tn+Fp+Fn)\n",
    "R= Tp/(Tp+Fn)\n",
    "F1= (2*R*P)/(R+P)\n",
    "\n",
    "print('Precision = ',P)\n",
    "print('Recall = ',R)\n",
    "print('Accuracy = ', A)\n",
    "print('F1 Measure = ', F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
